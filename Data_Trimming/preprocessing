{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing_TFIDF.ipynb","provenance":[{"file_id":"1lA_G11CLzCdHdY3sfXdmISaVwIDwPf15","timestamp":1575146800182},{"file_id":"1Nhq2MohlePHJ-FpZWsKP8BI8MZkEBNAJ","timestamp":1575145814698}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"BqpW0ZHo7d_X","colab_type":"code","colab":{}},"source":["import json\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMWwQj0lCZqM","colab_type":"code","outputId":"49b315ca-c434-49ec-a8ea-87c62c30d879","executionInfo":{"status":"ok","timestamp":1575149994587,"user_tz":360,"elapsed":18190,"user":{"displayName":"Daniel Tang","photoUrl":"","userId":"09540227816050740255"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yEFiNGrj8AML","colab_type":"code","colab":{}},"source":["root_path = '/content/drive/My Drive/DSCI 303 Final Project/Data Trimming/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"syimYoiu7jAc","colab_type":"code","colab":{}},"source":["with open(root_path + 'trimmed_review_150k.json') as json_file: # Open json file to load\n","    data = json.load(json_file) # Load the data as a big dictionary"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5heRpu637kGe","colab_type":"code","colab":{}},"source":["df = pd.DataFrame(data['Review:Rating']) # Convert list of dictionaries {review, stars} to dataframe"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTMS94S8QvHe","colab_type":"code","colab":{}},"source":["def convert_lower_case(data):\n","    return np.char.lower(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"spZSleQqRhJs","colab_type":"code","outputId":"e2ef32b7-a44d-4c59-bca2-83830fd5919d","executionInfo":{"status":"ok","timestamp":1575150403368,"user_tz":360,"elapsed":840,"user":{"displayName":"Daniel Tang","photoUrl":"","userId":"09540227816050740255"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"4aXDIU_hQ0Xq","colab_type":"code","colab":{}},"source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","def remove_stop_words(data):\n","  \"\"\"\n","  Input: str\n","  Output: str\n","  Removes stop words like I, me, the, etc. For preprocessing the data\n","  \"\"\"\n","  stop_words = stopwords.words('english')\n","  words = word_tokenize(str(data))\n","  new_text = \"\"\n","  for w in words:\n","      if w not in stop_words and len(w) > 1:\n","          new_text = new_text + \" \" + w\n","  return new_text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xenOp-jLS88A","colab_type":"code","colab":{}},"source":["def remove_punctuation(data):\n","  \"\"\"\n","  Input: str\n","  Output: str\n","  Further preprocessing\n","  \"\"\"\n","  symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n","  for i in range(len(symbols)):\n","      data = np.char.replace(data, symbols[i], ' ')\n","      data = np.char.replace(data, \"  \", \" \")\n","  data = np.char.replace(data, ',', '')\n","  return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsHbFq-aTB5I","colab_type":"code","colab":{}},"source":["def remove_apostrophe(data):\n","  \"\"\"\n","  Input: str\n","  Output: str\n","  Further preprocessing\n","  \"\"\"\n","  return np.char.replace(data, \"'\", \"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UU2GtnsDUiNu","colab_type":"code","colab":{}},"source":["from nltk.stem import PorterStemmer\n","def stemming(data):\n","  \"\"\"\n","  Input: str\n","  Output: str\n","  Converts words to their stem. Ex: worked -> work. Removes suffix and affix. No need for lemmatization for TFIDF\n","  \"\"\"\n","  stemmer= PorterStemmer()\n","  \n","  tokens = word_tokenize(str(data))\n","  new_text = \"\"\n","  for w in tokens:\n","      new_text = new_text + \" \" + stemmer.stem(w)\n","  return new_text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U0D7NcXTWJ7H","colab_type":"code","outputId":"73a66d8f-0d2d-4cc5-ec3d-684cc54b70a3","executionInfo":{"status":"ok","timestamp":1575151522738,"user_tz":360,"elapsed":4149,"user":{"displayName":"Daniel Tang","photoUrl":"","userId":"09540227816050740255"}},"colab":{"base_uri":"https://localhost:8080/","height":138}},"source":["!pip install num2words"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting num2words\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n","\r\u001b[K     |███▎                            | 10kB 33.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.3MB/s \n","\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words) (0.6.2)\n","Installing collected packages: num2words\n","Successfully installed num2words-0.5.10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ItlGQV9uV3Bs","colab_type":"code","colab":{}},"source":["from num2words import num2words\n","def convert_numbers(data):\n","    tokens = word_tokenize(str(data))\n","    new_text = \"\"\n","    for w in tokens:\n","        try:\n","            w = num2words(int(w))\n","        except:\n","            a = 0\n","        new_text = new_text + \" \" + w\n","    new_text = np.char.replace(new_text, \"-\", \" \")\n","    return new_text"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-8iBFfWZaHir","colab_type":"text"},"source":["**Pipeline** below for preprocessing our text in our dataframe using the functions above:"]},{"cell_type":"code","metadata":{"id":"gFg8K7H3Q6Ii","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: convert_lower_case(x)) #Convert each review to lowercase"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-wcZaZwSjdZ","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: remove_punctuation(x)) #Remove punctuation from each review"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRqEMA5lW4UX","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: remove_apostrophe(x)) #Remove apostrophes from each review"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"li0CYXZZXUYf","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: remove_stop_words(x)) #Remove stop words from each review"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rcjP5mrcXgVJ","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: convert_numbers(x)) #Convert numerics to string equivalents"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRLaKDriXq9l","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: stemming(x)) #Stem all the words from each review"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPF2YD7iX-yn","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: remove_punctuation(x)) #Repeated just in case punctuation was reintroduced"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PTRUYy3Yxvu","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: convert_numbers(x)) #Just in case more numbers were reintroduced"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ECnwj1cfY8CV","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: stemming(x)) #Just in case numbers needed to be stemmed again "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-gZ3f_oZk6h","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: remove_punctuation(x)) #Repeated because num2words does give some hyphens and commas"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-N0MvL6Z1G4","colab_type":"code","colab":{}},"source":["df['review'] = df['review'].apply(lambda x: remove_stop_words(x)) #Repeated because num2words does give stop words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dml9PZxT_B7Q","colab_type":"code","outputId":"91f1dc74-82e7-46b7-b925-0bae13bd4c90","executionInfo":{"status":"error","timestamp":1575191318540,"user_tz":360,"elapsed":1276,"user":{"displayName":"Daniel Tang","photoUrl":"","userId":"09540227816050740255"}},"colab":{"base_uri":"https://localhost:8080/","height":162}},"source":["df.head(6)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6ab08b3e117d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"code","metadata":{"id":"HlPqblE-be23","colab_type":"code","colab":{}},"source":["data = df.to_json(orient='records')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rleD7qt-b3dQ","colab_type":"code","outputId":"6e40c8fc-5194-4de4-ddb7-ead163ee2b2e","executionInfo":{"status":"error","timestamp":1575191997627,"user_tz":360,"elapsed":1126,"user":{"displayName":"Daniel Tang","photoUrl":"","userId":"09540227816050740255"}},"colab":{"base_uri":"https://localhost:8080/","height":178}},"source":["with open(root_path + \"preprocessed_150k_reviews.json\", 'w') as outfile:\n","    json.dump(data, outfile)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8df39cf6cb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"preprocessed_150k_reviews.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'root_path' is not defined"]}]},{"cell_type":"code","metadata":{"id":"OmnxUatN6LST","colab_type":"code","outputId":"0085919a-1148-4d72-d103-e6a7d1a094e3","executionInfo":{"status":"ok","timestamp":1575161011179,"user_tz":360,"elapsed":4365,"user":{"displayName":"Daniel Tang","photoUrl":"","userId":"09540227816050740255"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["sample_data\n"],"name":"stdout"}]}]}